{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b689b4a",
   "metadata": {},
   "source": [
    "# Getting Started\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "This demo uses python and a Jupyter notebook. It is recommended to use Python 3.7 or greater. Visit [python.org](https://www.python.org/downloads/) and [jupyter.org](https://jupyter.org/install) for installation instructions.\n",
    "\n",
    "_PyTorch has great instructions on how to [get started](https://pytorch.org/get-started/locally/) with these fundamental prerequisites._\n",
    "\n",
    "Create a python virtual environment with conda or venv.\n",
    "\n",
    "conda:\n",
    "\n",
    "  1. `conda create --name demo python=3.7`\n",
    "  1. `activate demo`\n",
    "\n",
    "venv:\n",
    "\n",
    "  1. `python -m venv .env`\n",
    "  1. `source ./env/bin/activate`\n",
    "\n",
    "PyTorch must be installed before this notebook can be run. Visit [pytorch.org](https://pytorch.org/get-started/locally/) for instructions.\n",
    "\n",
    "For initial testing, UGRC used a CPU-only install with conda on windows.\n",
    "\n",
    "- `conda install pytorch torchvision cpuonly -c pytorch`\n",
    "\n",
    "And a pip install on MacOS\n",
    "\n",
    "1. `pip install torch torchvision`\n",
    "\n",
    "YOLOv5 need to be installed for the TowerScout weights to be applied. Quick start instructions for YOLOv5 can be found on [GitHub](https://github.com/ultralytics/yolov5)\n",
    "\n",
    "1. `git clone https://github.com/ultralytics/yolov5`\n",
    "2. `cd yolov5`\n",
    "3. `pip install -r requirements.txt`\n",
    "\n",
    "The sample images should be tiled to an appropriate tile size for processing by YOLOv5 (UGRC used 512x512 pixel tiles)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "41832390",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import python libraries\n",
    "\n",
    "from pathlib import Path\n",
    "from time import perf_counter\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc29ea84",
   "metadata": {},
   "source": [
    "### Load TowerScout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ce3a873f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv5 ðŸš€ v6.1-246-g2dd3db0 Python-3.9.13 torch-1.11.0 CPU\n",
      "\n",
      "Fusing layers... \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients\n",
      "Adding AutoShape... \n"
     ]
    }
   ],
   "source": [
    "current_path = Path().resolve()\n",
    "\n",
    "# Set up path to the yolov5 directory and local repo\n",
    "yolov5_src_path = current_path / 'yolov5'\n",
    "\n",
    "# Set up path to model weights file and load the TowerScout model\n",
    "towerscout_weights_path = current_path / 'tower_scout' / 'xl_250_best.pt'\n",
    "\n",
    "model = torch.hub.load(yolov5_src_path, 'custom', path=towerscout_weights_path, source='local')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "677dcbb3",
   "metadata": {},
   "source": [
    "### Run TowerScout\n",
    "If more than 100 images are in the tile directory, you may need to break the images into batches of 100 images to avoid a memory allocation error.  Results will be saved in the `\\runs\\detect\\exp` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ff71f823",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saved 1 image to \u001b[1mruns/detect/exp2\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed (1 images): 0.40s\n",
      "image 1/1: 1334x2000 14 persons\n",
      "Speed: 196.9ms pre-process, 203.7ms inference, 1.4ms NMS per image at shape (1, 3, 448, 640)\n",
      "Total time elapsed (1 images): 0.48s\n"
     ]
    }
   ],
   "source": [
    "# Set location of image tiles and cd into that directory\n",
    "tile_folder = current_path / 'image_tiles'\n",
    "\n",
    "# Build list of images in tile directory\n",
    "images = list(tile_folder.glob('**/*.jpg'))\n",
    "\n",
    "image_count = len(images)\n",
    "start = perf_counter()\n",
    "\n",
    "for i in range(image_count):\n",
    "    batch_start = perf_counter()\n",
    "    batch = images[i:i+100]\n",
    "\n",
    "    results = model(images)\n",
    "    print(f'Time elapsed ({len(batch)} images): {perf_counter() - batch_start:.2f}s')\n",
    "\n",
    "    results.print()\n",
    "    results.save()\n",
    "\n",
    "print(f'Total time elapsed ({image_count} images): {perf_counter() - start:.2f}s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f1851e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
