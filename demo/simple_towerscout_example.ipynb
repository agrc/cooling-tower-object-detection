{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f71bd1b",
   "metadata": {},
   "source": [
    "# Getting Started\n",
    "\n",
    "The PyTorch python library must be installed before this notebook can be run. Visit [pytorch.org](https://pytorch.org/) for instructions. For initial testing, UGRC used a CPU-only install with conda.\n",
    "\n",
    "- `conda install pytorch torchvision cpuonly -c pytorch`\n",
    "\n",
    "The YOLOv5 dependencies will need to be installed. Quick start instructions for YOLOv5 can be found on [GitHub](https://github.com/ultralytics/yolov5)\n",
    "\n",
    "1. `git clone https://github.com/ultralytics/yolov5`\n",
    "1. `cd yolov5`\n",
    "1. `pip install -r requirements.txt`\n",
    "\n",
    "The sample images should already be tiled to the appropriate tile size for processing by TowerScout (UGRC used 512x512 pixel tiles)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12bec1fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import python libraries\n",
    "\n",
    "import torch\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f2e5f93",
   "metadata": {},
   "source": [
    "### Load TowerScout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe1cff28",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv5  v6.1-246-g2dd3db0 Python-3.7.11 torch-1.10.2 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 476 layers, 87198694 parameters, 0 gradients\n",
      "Adding AutoShape... \n"
     ]
    }
   ],
   "source": [
    "base_dir = os.getcwd()\n",
    "\n",
    "# Set up path to the yolov5 directory and local repo\n",
    "yolo_path = os.path.join(base_dir, 'yolov5')\n",
    "\n",
    "# Set up path to model weights file and load the TowerScout model\n",
    "model_path = os.path.join(base_dir, r'tower_scout\\xl_250_best.pt')\n",
    "model = torch.hub.load(yolo_path, 'custom', path=model_path, source='local')  # load from local repo\n",
    "\n",
    "# Set location of image tiles and cd into that directory\n",
    "tile_folder = os.path.join(base_dir, 'image_tiles')\n",
    "os.chdir(tile_folder)\n",
    "\n",
    "# Build list of images in tile directory\n",
    "imgs = [f for f in listdir(tile_folder) if isfile(join(tile_folder, f)) and f.endswith(\".jpg\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9afb466e",
   "metadata": {},
   "source": [
    "### Run TowerScout\n",
    "If more than 100 images are in the tile directory, you may need to break the images into batches of 100 images to avoid a memory allocation error.  Results will be saved in the `image_tiles\\runs\\detect\\exp` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64308539",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed (19 images): 69.91s\n",
      "image 1/19: 512x512 (no detections)\n",
      "image 2/19: 512x512 1 ct\n",
      "image 3/19: 512x512 3 cts\n",
      "image 4/19: 512x512 2 cts\n",
      "image 5/19: 512x512 1 ct\n",
      "image 6/19: 512x512 4 cts\n",
      "image 7/19: 512x512 5 cts\n",
      "image 8/19: 512x512 1 ct\n",
      "image 9/19: 512x512 1 ct\n",
      "image 10/19: 512x512 1 ct\n",
      "image 11/19: 512x512 1 ct\n",
      "image 12/19: 512x512 1 ct\n",
      "image 13/19: 512x512 3 cts\n",
      "image 14/19: 512x512 1 ct\n",
      "image 15/19: 512x512 1 ct\n",
      "image 16/19: 512x512 2 cts\n",
      "image 17/19: 512x512 1 ct\n",
      "image 18/19: 512x512 2 cts\n",
      "image 19/19: 512x512 1 ct\n",
      "Speed: 13.4ms pre-process, 3664.2ms inference, 1.1ms NMS per image at shape (19, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saved 19 images to \u001b[1mruns\\detect\\exp\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# If more than 100 images, break into batches of 100, run 1 batch at a time\n",
    "batch_1 = imgs[:100]\n",
    "batch_2 = imgs[100:200]\n",
    "batch_3 = imgs[200:]\n",
    "\n",
    "start = time.time()\n",
    "results = model(imgs)\n",
    "# results = model(batch_1)   # if using batches, use this line to run on the first batch\n",
    "print(f\"Time elapsed ({len(imgs)} images): {time.time() - start:.2f}s\")\n",
    "\n",
    "# Print results\n",
    "results.print()\n",
    "\n",
    "# Save detection images\n",
    "results.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd30f359",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
